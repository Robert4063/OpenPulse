"""
Commentæ•°æ®æ¸…æ´—è„šæœ¬
åŠŸèƒ½:
1. é¡ºåºå¤„ç†æ¯ä¸ªJSONæ–‡ä»¶
2. æŒ‰issue_urlåˆ†ç»„,å°†åŒä¸€ä¸ªé—®é¢˜çš„æ‰€æœ‰commentsæ”¾åœ¨ä¸€èµ·
3. åªä¿ç•™æŒ‡å®šå­—æ®µ: id, body, user, created_at, updated_at, html_url, issue_url
4. è¾“å‡ºç»“æ„: æ¯ä¸ªåŸå§‹æ–‡ä»¶å¯¹åº”ä¸€ä¸ªè¾“å‡ºæ–‡ä»¶

ç”¨æ³•:
    python clean_comment_data.py          # äº¤äº’å¼ï¼Œéœ€è¦ç¡®è®¤
    python clean_comment_data.py --yes    # è·³è¿‡ç¡®è®¤ç›´æ¥æ‰§è¡Œ
"""
import os
import sys
import json
import re
from typing import List, Dict, Optional
from collections import defaultdict

# é…ç½®
COMMENT_DIR = os.path.join(os.path.dirname(os.path.dirname(__file__)), "data", "comment")
OUTPUT_DIR = os.path.join(os.path.dirname(os.path.dirname(__file__)), "data", "comment_cleaned")

# éœ€è¦ä¿ç•™çš„å­—æ®µ
KEEP_FIELDS = ["id", "body", "user", "created_at", "updated_at", "html_url", "issue_url"]


def clean_json_content(content: str) -> str:
    """æ¸…ç†JSONå†…å®¹ä¸­çš„æ§åˆ¶å­—ç¬¦å’Œæ ¼å¼é—®é¢˜"""
    # ç§»é™¤å¯èƒ½çš„UTF-8 BOM
    if content.startswith('\ufeff'):
        content = content[1:]
    
    # ç§»é™¤æ‰€æœ‰æ§åˆ¶å­—ç¬¦ï¼ˆ\x00-\x1fï¼‰ï¼Œä½†ä¿ç•™æ¢è¡Œç¬¦(\n=\x0a)å’Œå›è½¦ç¬¦(\r=\x0d)
    # è¿™äº›æ§åˆ¶å­—ç¬¦åœ¨JSONå­—ç¬¦ä¸²ä¸­æ˜¯éæ³•çš„
    content = re.sub(r'[\x00-\x09\x0b\x0c\x0e-\x1f\x7f]', '', content)
     
    return content.strip()


def deep_clean_json_string(content: str) -> str:
    """
    æ·±åº¦æ¸…ç†JSONå­—ç¬¦ä¸²ä¸­çš„æ§åˆ¶å­—ç¬¦
    å¤„ç†å­—ç¬¦ä¸²å€¼å†…éƒ¨çš„æ§åˆ¶å­—ç¬¦ï¼ˆåœ¨å¼•å·å†…çš„å†…å®¹ï¼‰
    ä½¿ç”¨æ›´æ¿€è¿›çš„æ¸…ç†ç­–ç•¥
    """
    # ç­–ç•¥1: ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æ›¿æ¢å­—ç¬¦ä¸²å†…çš„æ§åˆ¶å­—ç¬¦
    # åŒ¹é…JSONå­—ç¬¦ä¸²å¹¶æ¸…ç†å…¶ä¸­çš„æ§åˆ¶å­—ç¬¦
    def clean_string_value(match):
        s = match.group(0)
        # ç§»é™¤å­—ç¬¦ä¸²å†…çš„æ§åˆ¶å­—ç¬¦ï¼ˆé™¤äº†å·²è½¬ä¹‰çš„ï¼‰
        # ä¿ç•™ \n \r \t çš„è½¬ä¹‰å½¢å¼ï¼Œä½†ç§»é™¤è£¸éœ²çš„æ§åˆ¶å­—ç¬¦
        cleaned = []
        i = 0
        while i < len(s):
            char = s[i]
            if char == '\\' and i + 1 < len(s):
                # ä¿ç•™è½¬ä¹‰åºåˆ—
                cleaned.append(char)
                cleaned.append(s[i + 1])
                i += 2
                continue
            # ç§»é™¤æ§åˆ¶å­—ç¬¦ (0x00-0x1F, 0x7F)
            if ord(char) < 32 or ord(char) == 127:
                # æ¢è¡Œå’Œåˆ¶è¡¨ç¬¦è½¬æ¢ä¸ºç©ºæ ¼
                if char in '\n\r\t':
                    cleaned.append(' ')
                # å…¶ä»–æ§åˆ¶å­—ç¬¦ç›´æ¥ç§»é™¤
                i += 1
                continue
            cleaned.append(char)
            i += 1
        return ''.join(cleaned)
    
    # åŒ¹é…JSONå­—ç¬¦ä¸² (åŒ…æ‹¬è½¬ä¹‰çš„å¼•å·)
    # è¿™ä¸ªæ­£åˆ™è¡¨è¾¾å¼åŒ¹é…: "..." åŒ…æ‹¬è½¬ä¹‰çš„å¼•å· \"
    try:
        result = re.sub(r'"(?:[^"\\]|\\.)*"', clean_string_value, content)
        return result
    except Exception:
        # å¦‚æœæ­£åˆ™å¤±è´¥ï¼Œä½¿ç”¨é€å­—ç¬¦æ–¹æ³•
        pass
    
    # å¤‡ç”¨ç­–ç•¥: é€å­—ç¬¦å¤„ç†
    result = []
    in_string = False
    escape_next = False
    
    for char in content:
        if escape_next:
            result.append(char)
            escape_next = False
            continue
            
        if char == '\\' and in_string:
            result.append(char)
            escape_next = True
            continue
            
        if char == '"' and not escape_next:
            in_string = not in_string
            result.append(char)
            continue
        
        # å¦‚æœåœ¨å­—ç¬¦ä¸²å†…éƒ¨ï¼Œå¤„ç†æ§åˆ¶å­—ç¬¦
        if in_string:
            if ord(char) < 32 or ord(char) == 127:
                # æ¢è¡Œ/å›è½¦/åˆ¶è¡¨ç¬¦è½¬æ¢ä¸ºç©ºæ ¼
                if char in '\n\r\t':
                    result.append(' ')
                # å…¶ä»–æ§åˆ¶å­—ç¬¦ç›´æ¥è·³è¿‡
                continue
            else:
                result.append(char)
        else:
            # ä¸åœ¨å­—ç¬¦ä¸²å†…ï¼Œä¿ç•™æ­£å¸¸çš„æ¢è¡Œç­‰
            if ord(char) < 32 and char not in '\n\r\t':
                continue
            result.append(char)
    
    return ''.join(result)


def try_parse_json(content: str, filepath: str) -> Optional[List[Dict]]:
    """å°è¯•å¤šç§æ–¹æ³•è§£æJSON"""
    filename = os.path.basename(filepath)
    
    # æ–¹æ³•1: ç›´æ¥è§£æ
    try:
        data = json.loads(content)
        if isinstance(data, list):
            return data
        else:
            print(f"  âš ï¸  {filename}: æ•°æ®ä¸æ˜¯æ•°ç»„æ ¼å¼")
            return None
    except json.JSONDecodeError as e:
        error_msg = str(e)
        
        # æ–¹æ³•2: å¦‚æœæ˜¯"Extra data"é”™è¯¯ï¼Œå°è¯•åªè¯»å–ç¬¬ä¸€ä¸ªå®Œæ•´çš„JSONæ•°ç»„
        if "Extra data" in error_msg:
            print(f"  âš ï¸  {filename}: æ£€æµ‹åˆ°Extra dataé”™è¯¯ï¼Œå°è¯•ä¿®å¤...")
            try:
                decoder = json.JSONDecoder()
                data, idx = decoder.raw_decode(content)
                if isinstance(data, list):
                    remaining = content[idx:].strip()
                    if remaining:
                        print(f"     è­¦å‘Š: æ–‡ä»¶æœ«å°¾æœ‰ {len(remaining)} å­—ç¬¦è¢«å¿½ç•¥")
                    return data
            except Exception as e2:
                print(f"     ä¿®å¤å¤±è´¥: {e2}")
        
        # æ–¹æ³•3: å¦‚æœæ˜¯æ§åˆ¶å­—ç¬¦é”™è¯¯ï¼Œå°è¯•æ·±åº¦æ¸…ç†
        if "control character" in error_msg.lower():
            print(f"  âš ï¸  {filename}: æ£€æµ‹åˆ°æ§åˆ¶å­—ç¬¦é”™è¯¯ï¼Œå°è¯•æ·±åº¦æ¸…ç†...")
            try:
                cleaned = deep_clean_json_string(content)
                data = json.loads(cleaned)
                if isinstance(data, list):
                    print(f"     æ·±åº¦æ¸…ç†æˆåŠŸï¼Œè§£æ {len(data)} æ¡æ•°æ®")
                    return data
            except json.JSONDecodeError as e3:
                # å¦‚æœè¿˜æ˜¯å¤±è´¥ï¼Œå°è¯•æ›´æ¿€è¿›çš„æ¸…ç†ï¼šç§»é™¤æ‰€æœ‰æ§åˆ¶å­—ç¬¦
                print(f"     æ·±åº¦æ¸…ç†ä»æœ‰é—®é¢˜: {e3}")
                print(f"     å°è¯•æ¿€è¿›æ¸…ç†...")
                try:
                    # ç§»é™¤æ‰€æœ‰æ§åˆ¶å­—ç¬¦ï¼ˆåŒ…æ‹¬å­—ç¬¦ä¸²å†…çš„æ¢è¡Œï¼‰
                    aggressive_cleaned = re.sub(r'[\x00-\x1f\x7f]', ' ', content)
                    data = json.loads(aggressive_cleaned)
                    if isinstance(data, list):
                        print(f"     æ¿€è¿›æ¸…ç†æˆåŠŸï¼Œè§£æ {len(data)} æ¡æ•°æ®")
                        return data
                except Exception as e4:
                    print(f"     æ¿€è¿›æ¸…ç†å¤±è´¥: {e4}")
        
        # æ–¹æ³•4: å°è¯•ä¿®å¤æˆªæ–­çš„JSON
        try:
            last_complete = content.rfind('}')
            if last_complete > 0:
                truncated = content[:last_complete+1]
                if not truncated.rstrip().endswith(']'):
                    truncated = truncated + ']'
                data = json.loads(truncated)
                if isinstance(data, list):
                    print(f"  âš ï¸  {filename}: ä¿®å¤æˆªæ–­JSONæˆåŠŸï¼Œè§£æ {len(data)} æ¡æ•°æ®")
                    return data
        except Exception:
            pass
        
        print(f"  âŒ {filename}: JSONè§£æå¤±è´¥ - {error_msg}")
        return None


def clean_comment(comment: Dict) -> Dict:
    """æ¸…æ´—å•æ¡comment,åªä¿ç•™æŒ‡å®šå­—æ®µ"""
    cleaned = {}
    for field in KEEP_FIELDS:
        if field in comment:
            cleaned[field] = comment[field]
        else:
            cleaned[field] = None
    return cleaned


def group_comments_by_issue(comments: List[Dict]) -> Dict[str, List[Dict]]:
    """æŒ‰issue_urlåˆ†ç»„comments"""
    grouped = defaultdict(list)
    
    for comment in comments:
        issue_url = comment.get("issue_url")
        if issue_url:
            grouped[issue_url].append(comment)
        else:
            grouped["unknown"].append(comment)
    
    # å¯¹æ¯ä¸ªåˆ†ç»„å†…çš„commentsæŒ‰created_atæ’åº
    result = {}
    for issue_url, issue_comments in grouped.items():
        sorted_comments = sorted(
            issue_comments,
            key=lambda x: x.get("created_at") or ""
        )
        result[issue_url] = sorted_comments
    
    return result


def process_single_file(input_filepath: str, output_filepath: str) -> tuple[bool, dict]:
    """
    å¤„ç†å•ä¸ªJSONæ–‡ä»¶
    
    Returns:
        (æ˜¯å¦æˆåŠŸ, ç»Ÿè®¡ä¿¡æ¯)
    """
    filename = os.path.basename(input_filepath)
    stats = {
        "total_comments": 0,
        "issue_count": 0
    }
    
    try:
        # è¯»å–åŸå§‹æ•°æ®
        with open(input_filepath, 'r', encoding='utf-8', errors='ignore') as f:
            content = f.read()
        
        # æ¸…ç†å†…å®¹
        content = clean_json_content(content)
        
        # è§£æJSON
        data = try_parse_json(content, input_filepath)
        
        if data is None:
            return False, stats
        
        # æ¸…æ´—æ¯æ¡comment
        cleaned_comments = [clean_comment(comment) for comment in data]
        stats["total_comments"] = len(cleaned_comments)
        
        # æŒ‰issue_urlåˆ†ç»„
        grouped = group_comments_by_issue(cleaned_comments)
        stats["issue_count"] = len(grouped)
        
        # æ„å»ºè¾“å‡ºæ•°æ®ç»“æ„
        output_data = {
            "source_file": filename,
            "total_comments": len(cleaned_comments),
            "issue_count": len(grouped),
            "issues": []
        }
        
        # æŒ‰issue_urlæ’åºè¾“å‡º
        for issue_url in sorted(grouped.keys()):
            issue_comments = grouped[issue_url]
            output_data["issues"].append({
                "issue_url": issue_url,
                "comment_count": len(issue_comments),
                "comments": issue_comments
            })
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs(os.path.dirname(output_filepath), exist_ok=True)
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        with open(output_filepath, 'w', encoding='utf-8') as f:
            json.dump(output_data, f, ensure_ascii=False, indent=2)
        
        return True, stats
        
    except Exception as e:
        print(f"  âŒ {filename}: å¤„ç†å¤±è´¥ - {e}")
        return False, stats


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("ğŸ§¹ Commentæ•°æ®æ¸…æ´—å·¥å…·")
    print("=" * 60)
    print(f"\nåŠŸèƒ½è¯´æ˜:")
    print(f"  1. åªä¿ç•™å­—æ®µ: {', '.join(KEEP_FIELDS)}")
    print(f"  2. æŒ‰issue_urlåˆ†ç»„comments")
    print(f"  3. æ¯ä¸ªæ–‡ä»¶ç‹¬ç«‹å¤„ç†")
    print(f"\nè¾“å…¥ç›®å½•: {COMMENT_DIR}")
    print(f"è¾“å‡ºç›®å½•: {OUTPUT_DIR}")
    
    # æ£€æŸ¥è¾“å…¥ç›®å½•
    if not os.path.exists(COMMENT_DIR):
        print(f"\nâŒ è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {COMMENT_DIR}")
        return
    
    # è·å–æ‰€æœ‰JSONæ–‡ä»¶
    json_files = [f for f in os.listdir(COMMENT_DIR) if f.endswith('.json')]
    json_files.sort()
    
    print(f"\næ‰¾åˆ° {len(json_files)} ä¸ªJSONæ–‡ä»¶")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰ --yes å‚æ•°è·³è¿‡ç¡®è®¤
    if "--yes" not in sys.argv and "-y" not in sys.argv:
        confirm = input("\nç¡®è®¤å¼€å§‹å¤„ç†? (y/n): ").strip().lower()
        if confirm != 'y':
            print("âŒ æ“ä½œå·²å–æ¶ˆ")
            return
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    
    print("\n" + "-" * 60)
    print("å¼€å§‹å¤„ç†...")
    print("-" * 60 + "\n")
    
    # ç»Ÿè®¡ä¿¡æ¯
    total_stats = {
        "success": 0,
        "failed": 0,
        "total_comments": 0,
        "total_issues": 0,
        "failed_files": []
    }
    
    # é¡ºåºå¤„ç†æ¯ä¸ªæ–‡ä»¶
    for i, filename in enumerate(json_files, 1):
        input_path = os.path.join(COMMENT_DIR, filename)
        output_path = os.path.join(OUTPUT_DIR, filename)
        
        print(f"[{i}/{len(json_files)}] å¤„ç†: {filename}")
        
        success, stats = process_single_file(input_path, output_path)
        
        if success:
            total_stats["success"] += 1
            total_stats["total_comments"] += stats["total_comments"]
            total_stats["total_issues"] += stats["issue_count"]
            print(f"  âœ“ å®Œæˆ: {stats['total_comments']:,} comments, {stats['issue_count']} issues")
        else:
            total_stats["failed"] += 1
            total_stats["failed_files"].append(filename)
    
    # æ‰“å°æœ€ç»ˆç»Ÿè®¡
    print("\n" + "=" * 60)
    print("ğŸ“Š å¤„ç†ç»Ÿè®¡")
    print("=" * 60)
    print(f"\næ–‡ä»¶å¤„ç†:")
    print(f"  - æˆåŠŸ: {total_stats['success']}/{len(json_files)}")
    print(f"  - å¤±è´¥: {total_stats['failed']}")
    
    if total_stats["failed_files"]:
        print(f"\nå¤±è´¥çš„æ–‡ä»¶:")
        for f in total_stats["failed_files"]:
            print(f"  - {f}")
    
    print(f"\næ•°æ®ç»Ÿè®¡:")
    print(f"  - æ€»comments: {total_stats['total_comments']:,}")
    print(f"  - æ€»issues: {total_stats['total_issues']:,}")
    
    print(f"\nè¾“å‡ºç›®å½•: {OUTPUT_DIR}")
    print("\n" + "=" * 60)
    print("âœ… å¤„ç†å®Œæˆ!")
    print("=" * 60)


if __name__ == "__main__":
    main()
